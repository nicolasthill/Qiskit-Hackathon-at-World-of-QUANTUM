{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction/Motivation\n",
    "\n",
    "## Theory\n",
    "\n",
    "# 1. Optimization\n",
    "\n",
    "Coming back to our example from just now, trying to optimize y while controlling x thus we are looking for a function f which generates a solution y as y = f(x). The key assumption of any attempt at optimization is the existence of an optimal solution. Alternatively a solution which is sufficiently optimal, generally called $\\hat{y}$. But how do we know how good our solution is? We need to figure out how close it is to the theoretical optimal solution, for this we need a cost function also known as the loss function or simply the loss which we try to minimize\n",
    "\n",
    "A cost function can take many different shapes which depend on the number of parameters, application etc. a general way of writing it is. The simplest example for a cost function is one dimensional meaning we have a curve of which we find the minimum. A tricky situation is non-convex loss function which can lead to being stuck at a local minimum.\n",
    "\n",
    "To make the transition to quantum mechanics, we have to find a way to encode the loss function in a quantum mechanical system. Thinking back to any sort of physics problem, we know that the system always takes the path of least resistance, or occupies the state of least energy. We exploit this very principle when we encode our optimization problem into the hamiltonian of a system. This allows us to find the solution to the problem simply as the ground state of our system. A major advantage of this to the classical state is that the likelihood of finding local minima is a lot lower because of a process called quantum annealing.\n",
    "\n",
    "For Quantum annealing we start the state of the wuantum system in a uniform superposition of all possible states. Then the system evolves following the time-dependent Schr√∂dinger equation, the quantum-mechanical evolution of physical systems as determined by its Hamiltonian. Thus, the amplitudes of all candidate states keep changing, XXX ending up in the ground state: our solution is found.\n",
    "\n",
    "# 2. QAOA\n",
    "\n",
    "After talking about the general differences between optimization in a classical and a quantum scenario we will continue the lecture looking at a specific optimization algorithm, namely QAOA which stands for Quantum Approximate Optimization Algorithm meaning we have an algorithm which gives an approximately optimal solution using quantum methods.\n",
    "\n",
    "\n",
    "## Implementation\n",
    "\n",
    "## Qiskit\n",
    "\n",
    "## Fields of Application"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
